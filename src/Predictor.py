import torch
import pandas as pd
import logging
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.calibration import CalibratedClassifierCV
from src.NeuralNetTrainer import Net

# –†–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
torch.serialization.add_safe_globals([
    StandardScaler,
    np._core.multiarray._reconstruct,
    np.ndarray,
    np.dtype,
    np.frombuffer
])

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CourseRecommender:
    def __init__(self, model_path: str = None):
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.calibration_factor = 0.7  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

        if model_path:
            self.load_model(model_path)

    def load_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ scaler'–∞"""
        try:
            checkpoint = torch.load(model_path, weights_only=False)
            self.model = Net(len(checkpoint['feature_names']))
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            self.scaler = checkpoint['scaler']
            self.feature_names = checkpoint['feature_names']

            # –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫—É—Ä—Å–æ–≤
            if 'course_difficulty_weights' in checkpoint:
                self.difficulty_weights = checkpoint['course_difficulty_weights']
            else:
                self.difficulty_weights = {'Easy': 1.0, 'Medium': 0.9, 'Hard': 0.8}

            logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def calibrate_probability(self, raw_prob: float, difficulty: str) -> float:
        """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫—É—Ä—Å–∞"""
        # –ë–∞–∑–æ–≤–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
        calibrated = 0.5 + (raw_prob - 0.5) * self.calibration_factor

        # –£—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫—É—Ä—Å–∞
        calibrated *= self.difficulty_weights.get(difficulty, 1.0)

        # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã [0.05, 0.95]
        return max(0.05, min(0.95, calibrated))

    def prepare_student_data(self, student_data: dict) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        required_fields = {'gpa', 'year_of_study'}
        if not required_fields.issubset(student_data.keys()):
            missing = required_fields - student_data.keys()
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing}")

        for major in ['CS', 'Math', 'History', 'Physics']:
            if f'major_{major}' not in student_data:
                student_data[f'major_{major}'] = 0

        return pd.DataFrame([student_data], columns=self.feature_names).fillna(0)

    def recommend_courses(self, student_data: dict, courses_df: pd.DataFrame,
                          threshold: float = 0.5, top_n: int = 5) -> list:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫—É—Ä—Å–æ–≤ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π"""
        if not all([self.model, self.scaler, self.feature_names]):
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        recommendations = []
        student_df = self.prepare_student_data(student_data)

        for _, course in courses_df.iterrows():
            input_data = student_df.copy()
            input_data[f'category_{course["category"]}'] = 1
            input_data[f'difficulty_level_{course["difficulty_level"]}'] = 1
            input_data['credits'] = course['credits']

            input_scaled = self.scaler.transform(input_data)
            input_tensor = torch.tensor(input_scaled, dtype=torch.float32)

            with torch.no_grad():
                raw_proba = self.model(input_tensor).item()

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
            proba = self.calibrate_probability(raw_proba, course['difficulty_level'])

            recommendations.append({
                'course_id': course['course_id'],
                'course_name': course['name'],
                'category': course['category'],
                'difficulty': course['difficulty_level'],
                'raw_probability': raw_proba,
                'calibrated_probability': proba
            })

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
        filtered = [r for r in recommendations if r['calibrated_probability'] >= threshold]
        sorted_recommendations = sorted(filtered,
                                        key=lambda x: x['calibrated_probability'],
                                        reverse=True)

        return sorted_recommendations[:top_n]

    def print_recommendations(self, recommendations: list):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        if not recommendations:
            print("\nü§∑ –ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞–Ω–Ω–æ–º—É –ø–æ—Ä–æ–≥—É")
            return

        print("\nüéì –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –∫—É—Ä—Å—ã (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞):")
        for i, course in enumerate(recommendations, 1):
            diff_emoji = {
                'Easy': '‚≠ê',
                'Medium': '‚≠ê‚≠ê',
                'Hard': '‚≠ê‚≠ê‚≠ê'
            }.get(course['difficulty'], '')

            print(f"{i}. {course['course_name']} ({course['category']}) {diff_emoji}")
            print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç—å: {course['difficulty']}")
            print(f"   –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {course['calibrated_probability']:.2f}")
            print(f"   (–ò—Å—Ö–æ–¥–Ω–∞—è: {course['raw_probability']:.2f})")
            print("-" * 40)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == '__main__':
    try:
        recommender = CourseRecommender('C:/Users/dimas/CsvGenerator/src/course_recommender_nn.pt')

        # –¢–µ—Å—Ç–æ–≤—ã–µ —Å—Ç—É–¥–µ–Ω—Ç—ã
        test_students = [
            {
                'gpa': 3.0,
                'year_of_study': 3,
                'major_Math': 1,
                'major_CS': 0,
                'major_History': 0,
                'major_Physics': 0
            },
            {
                'gpa': 4.5,
                'year_of_study': 4,
                'major_CS': 1,
                'major_Math': 0,
                'major_History': 0,
                'major_Physics': 0
            }
        ]

        courses_df = pd.read_csv('C:/Users/dimas/CsvGenerator/data/courses.csv')

        for i, student in enumerate(test_students, 1):
            print(f"\n{'=' * 50}")
            print(f"üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ #{i}:")
            print(f"- –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å: {[k for k, v in student.items() if 'major_' in k and v == 1][0].split('_')[1]}")
            print(f"- GPA: {student['gpa']}")
            print(f"- –ì–æ–¥ –æ–±—É—á–µ–Ω–∏—è: {student['year_of_study']}")

            recommendations = recommender.recommend_courses(
                student,
                courses_df,
                threshold=0.4,  # –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                top_n=5
            )
            recommender.print_recommendations(recommendations)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")