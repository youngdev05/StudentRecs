import torch
import pandas as pd
import logging
import numpy as np
from sklearn.preprocessing import StandardScaler
from src.NeuralNetTrainer import Net

# –†–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
torch.serialization.add_safe_globals([
    StandardScaler,
    np._core.multiarray._reconstruct,
    np.ndarray,
    np.dtype,
    np.frombuffer
])

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CourseRecommender:
    def __init__(self, model_path: str = None):
        self.model = None
        self.scaler = None
        self.feature_names = None

        if model_path:
            self.load_model(model_path)

    def load_model(self, model_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ scaler'–∞"""
        try:
            # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ - –æ—Ç–∫–ª—é—á–∞–µ–º weights_only –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            checkpoint = torch.load(model_path, weights_only=False)
            self.model = Net(len(checkpoint['feature_names']))
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            self.scaler = checkpoint['scaler']
            self.feature_names = checkpoint['feature_names']
            logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            raise


    def prepare_student_data(self, student_data: dict) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        required_fields = {'gpa', 'year_of_study'}
        if not required_fields.issubset(student_data.keys()):
            missing = required_fields - student_data.keys()
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing}")

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª–µ–π
        for major in ['CS', 'Math', 'History', 'Physics']:
            if f'major_{major}' not in student_data:
                student_data[f'major_{major}'] = 0

        return pd.DataFrame([student_data], columns=self.feature_names).fillna(0)

    def recommend_courses(self, student_data: dict, courses_df: pd.DataFrame, threshold: float = 0.5) -> list:
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∫—É—Ä—Å–æ–≤ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        if not all([self.model, self.scaler, self.feature_names]):
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        recommendations = []
        student_df = self.prepare_student_data(student_data)

        for _, course in courses_df.iterrows():
            # –ö–æ–ø–∏—Ä—É–µ–º –∏ –¥–æ–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            input_data = student_df.copy()
            input_data[f'category_{course["category"]}'] = 1
            input_data[f'difficulty_level_{course["difficulty_level"]}'] = 1
            input_data['credits'] = course['credits']

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            input_scaled = self.scaler.transform(input_data)
            input_tensor = torch.tensor(input_scaled, dtype=torch.float32)

            with torch.no_grad():
                proba = self.model(input_tensor).item()

            if proba >= threshold:
                recommendations.append({
                    'course_id': course['course_id'],
                    'course_name': course['name'],
                    'category': course['category'],
                    'difficulty': course['difficulty_level'],
                    'success_probability': proba
                })

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞
        return sorted(recommendations, key=lambda x: x['success_probability'], reverse=True)


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == '__main__':
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—è
        recommender = CourseRecommender('C:/Users/dimas/CsvGenerator/src/course_recommender_nn.pt')

        # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–∞
        student_data = {
            'gpa': 3.0,  # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è GPA
            'year_of_study': 3,  # –ò–∑–º–µ–Ω–∏—Ç–µ –≥–æ–¥ –æ–±—É—á–µ–Ω–∏—è
            'major_CS': 0,  # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏
            'major_Math': 1,
            'major_History': 0,
            'major_Physics': 0
        }

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –∫—É—Ä—Å–∞—Ö
        courses_df = pd.read_csv('C:/Users/dimas/CsvGenerator/data/courses.csv')

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = recommender.recommend_courses(student_data, courses_df)

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüéì –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –∫—É—Ä—Å—ã:")
        for course in recommendations[:5]:
            print(
                f"{course['course_name']} ({course['category']}) - –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞: {course['success_probability']:.2f}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
